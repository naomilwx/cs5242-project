{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0cef52a0",
      "metadata": {
        "id": "0cef52a0"
      },
      "source": [
        "# CS5242 Shopee Product Classification: Other Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94aed808",
      "metadata": {
        "id": "94aed808"
      },
      "source": [
        "* In this notebook, we aim to use some of the other types of Neural network building blocks to perform image classification.\n",
        "* These building blocks are added on to our CNN baseline model and evaluated."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fc650fb",
      "metadata": {
        "id": "9fc650fb"
      },
      "source": [
        "The two additional types of network experiments performed in this notebook are as follows:\n",
        "\n",
        "* Recurrent Neural Networks (RNN)\n",
        "* Attention Neural Networks (Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e6d703a",
      "metadata": {
        "id": "6e6d703a"
      },
      "source": [
        "## Imports and Config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Uncomment and run if running with file on drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# import os\n",
        "# os.chdir('gdrive/MyDrive/cs5242-project/cs5242-project')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPyX0-xjdAaC",
        "outputId": "302c2823-bce6-497f-e456-783e8abd925e"
      },
      "id": "GPyX0-xjdAaC",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "66b64a85",
      "metadata": {
        "id": "66b64a85"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from model import dataset, trainer\n",
        "from model import baseline_cnn_1, rnn_cnn, attention_cnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "38cd9d59",
      "metadata": {
        "id": "38cd9d59"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "num_epoch = 30\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d493f4",
      "metadata": {
        "id": "a3d493f4"
      },
      "source": [
        "## Data Import"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ca6b948",
      "metadata": {
        "id": "3ca6b948"
      },
      "source": [
        "* As previously, we use our dataset to import the set of images across categories.\n",
        "* The 9 categories are selected with the custom filtered 500 images from each of the categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6886afb2",
      "metadata": {
        "id": "6886afb2"
      },
      "outputs": [],
      "source": [
        "data = dataset.DataSet(max_num_img=500, crop=0.8, path='data/selected_images/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a7adc10b",
      "metadata": {
        "id": "a7adc10b",
        "outputId": "71d5f9a0-ed4c-4210-ef7c-24bcece28cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:11<00:00, 43.08it/s] \n",
            "100%|██████████| 500/500 [06:52<00:00,  1.21it/s]\n",
            "100%|██████████| 500/500 [06:51<00:00,  1.21it/s]\n",
            "100%|██████████| 500/500 [06:51<00:00,  1.21it/s]\n",
            "100%|██████████| 500/500 [06:52<00:00,  1.21it/s]\n",
            "100%|██████████| 500/500 [06:56<00:00,  1.20it/s]\n",
            "100%|██████████| 500/500 [06:58<00:00,  1.20it/s]\n",
            "100%|██████████| 500/500 [06:49<00:00,  1.22it/s]\n",
            "100%|██████████| 500/500 [07:00<00:00,  1.19it/s]\n"
          ]
        }
      ],
      "source": [
        "data.load_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d76fb4af",
      "metadata": {
        "id": "d76fb4af"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2143894",
      "metadata": {
        "id": "f2143894"
      },
      "source": [
        "* Before we proceed with these networks, we add in one evaluation of our baseline model to enable us to compare performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b2330d82",
      "metadata": {
        "id": "b2330d82"
      },
      "outputs": [],
      "source": [
        "baseline_cnn_1_model = baseline_cnn_1.BaselineCNN1(len(data.categories))\n",
        "torch.manual_seed(seed)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(baseline_cnn_1_model.parameters(), lr=4e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "578b90fe",
      "metadata": {
        "id": "578b90fe",
        "outputId": "71208a82-14c5-4bec-f106-7f62547573a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch   0]: Training loss: 1.735802 | Accuracy: 0.383810\n",
            "[Epoch   0]: Validation loss: 1.682558 | Accuracy: 0.377778 | Within 3: 0.740000\n",
            "[Epoch   1]: Training loss: 1.558757 | Accuracy: 0.465079\n",
            "[Epoch   1]: Validation loss: 1.587951 | Accuracy: 0.455556 | Within 3: 0.773333\n",
            "[Epoch   2]: Training loss: 1.455608 | Accuracy: 0.507937\n",
            "[Epoch   2]: Validation loss: 1.503304 | Accuracy: 0.484444 | Within 3: 0.766667\n",
            "[Epoch   3]: Training loss: 1.386036 | Accuracy: 0.522222\n",
            "[Epoch   3]: Validation loss: 1.781648 | Accuracy: 0.420000 | Within 3: 0.691111\n",
            "[Epoch   4]: Training loss: 1.323803 | Accuracy: 0.547619\n",
            "[Epoch   4]: Validation loss: 1.615260 | Accuracy: 0.440000 | Within 3: 0.733333\n",
            "[Epoch   5]: Training loss: 1.242632 | Accuracy: 0.577778\n",
            "[Epoch   5]: Validation loss: 1.393525 | Accuracy: 0.515556 | Within 3: 0.797778\n",
            "[Epoch   6]: Training loss: 1.197349 | Accuracy: 0.598413\n",
            "[Epoch   6]: Validation loss: 1.489513 | Accuracy: 0.526667 | Within 3: 0.802222\n",
            "[Epoch   7]: Training loss: 1.160527 | Accuracy: 0.610794\n",
            "[Epoch   7]: Validation loss: 1.328333 | Accuracy: 0.588889 | Within 3: 0.837778\n",
            "[Epoch   8]: Training loss: 1.112475 | Accuracy: 0.624444\n",
            "[Epoch   8]: Validation loss: 1.340035 | Accuracy: 0.560000 | Within 3: 0.813333\n",
            "[Epoch   9]: Training loss: 1.045686 | Accuracy: 0.645714\n",
            "[Epoch   9]: Validation loss: 1.283999 | Accuracy: 0.568889 | Within 3: 0.851111\n",
            "[Epoch  10]: Training loss: 1.010079 | Accuracy: 0.661905\n",
            "[Epoch  10]: Validation loss: 1.345264 | Accuracy: 0.537778 | Within 3: 0.824444\n",
            "[Epoch  11]: Training loss: 0.957164 | Accuracy: 0.678095\n",
            "[Epoch  11]: Validation loss: 1.346428 | Accuracy: 0.602222 | Within 3: 0.837778\n",
            "[Epoch  12]: Training loss: 0.919005 | Accuracy: 0.699365\n",
            "[Epoch  12]: Validation loss: 1.437072 | Accuracy: 0.553333 | Within 3: 0.844444\n",
            "[Epoch  13]: Training loss: 0.862388 | Accuracy: 0.717778\n",
            "[Epoch  13]: Validation loss: 1.314446 | Accuracy: 0.600000 | Within 3: 0.853333\n",
            "[Epoch  14]: Training loss: 0.797262 | Accuracy: 0.737460\n",
            "[Epoch  14]: Validation loss: 1.341163 | Accuracy: 0.553333 | Within 3: 0.831111\n",
            "[Epoch  15]: Training loss: 0.766387 | Accuracy: 0.756825\n",
            "[Epoch  15]: Validation loss: 1.594670 | Accuracy: 0.555556 | Within 3: 0.797778\n",
            "[Epoch  16]: Training loss: 0.692109 | Accuracy: 0.769206\n",
            "[Epoch  16]: Validation loss: 1.265807 | Accuracy: 0.617778 | Within 3: 0.877778\n",
            "[Epoch  17]: Training loss: 0.660796 | Accuracy: 0.793333\n",
            "[Epoch  17]: Validation loss: 1.621112 | Accuracy: 0.591111 | Within 3: 0.840000\n",
            "[Epoch  18]: Training loss: 0.593918 | Accuracy: 0.807302\n",
            "[Epoch  18]: Validation loss: 1.128772 | Accuracy: 0.657778 | Within 3: 0.888889\n",
            "[Epoch  19]: Training loss: 0.530623 | Accuracy: 0.838413\n",
            "[Epoch  19]: Validation loss: 1.195977 | Accuracy: 0.635556 | Within 3: 0.860000\n",
            "[Epoch  20]: Training loss: 0.489469 | Accuracy: 0.848571\n",
            "[Epoch  20]: Validation loss: 1.143129 | Accuracy: 0.642222 | Within 3: 0.884444\n",
            "[Epoch  21]: Training loss: 0.418537 | Accuracy: 0.881270\n",
            "[Epoch  21]: Validation loss: 1.168480 | Accuracy: 0.651111 | Within 3: 0.864444\n",
            "[Epoch  22]: Training loss: 0.366025 | Accuracy: 0.901270\n",
            "[Epoch  22]: Validation loss: 1.607844 | Accuracy: 0.544444 | Within 3: 0.831111\n",
            "[Epoch  23]: Training loss: 0.315517 | Accuracy: 0.921270\n",
            "[Epoch  23]: Validation loss: 1.308049 | Accuracy: 0.620000 | Within 3: 0.862222\n",
            "[Epoch  24]: Training loss: 0.247704 | Accuracy: 0.941905\n",
            "[Epoch  24]: Validation loss: 1.025510 | Accuracy: 0.671111 | Within 3: 0.904444\n",
            "[Epoch  25]: Training loss: 0.229621 | Accuracy: 0.947937\n",
            "[Epoch  25]: Validation loss: 1.023675 | Accuracy: 0.697778 | Within 3: 0.902222\n",
            "[Epoch  26]: Training loss: 0.209746 | Accuracy: 0.950476\n",
            "[Epoch  26]: Validation loss: 1.263489 | Accuracy: 0.640000 | Within 3: 0.888889\n",
            "[Epoch  27]: Training loss: 0.187066 | Accuracy: 0.954921\n",
            "[Epoch  27]: Validation loss: 1.219914 | Accuracy: 0.677778 | Within 3: 0.888889\n",
            "[Epoch  28]: Training loss: 0.144981 | Accuracy: 0.972063\n",
            "[Epoch  28]: Validation loss: 1.131426 | Accuracy: 0.675556 | Within 3: 0.884444\n",
            "[Epoch  29]: Training loss: 0.092850 | Accuracy: 0.989524\n",
            "[Epoch  29]: Validation loss: 1.145707 | Accuracy: 0.684444 | Within 3: 0.891111\n",
            "Best epoch:  25\n"
          ]
        }
      ],
      "source": [
        "mtrainer = trainer.Trainer(baseline_cnn_1_model, optimizer, criterion, data, batch_size)\n",
        "mtrainer.run_train(num_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1e9a62cf",
      "metadata": {
        "id": "1e9a62cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16e8e98-2378-4301-c31e-f65e24bee6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 64.55555555555556 %\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc, top_k, incorect_stats = mtrainer.run_test(mtrainer.testloader, 3, True)\n",
        "print(f'Accuracy of the network on the test images: {test_acc*100} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0659c922",
      "metadata": {
        "id": "0659c922"
      },
      "source": [
        "## Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf786b0",
      "metadata": {
        "id": "8bf786b0"
      },
      "source": [
        "* In this approach, we add an RNN layer over the baseline CNN model we implemented.\n",
        "* The RNN layer selected is a Long Short Term Memory (LSTM) layer from the Pytorch nn modules.\n",
        "    * We keep all other convolutional blocks the same as compared to the baseline CNN model.\n",
        "* The LSTM mechanism is implemented as follows:\n",
        "    * After passing through the convolutional blocks, the image is split into smaller patches\n",
        "    * These patches are then passed sequentially into the LSTM model.\n",
        "    * The number of hidden states in the LSTM is directly proportional to the number of patches in the image.\n",
        "* Following the LSTM layer, a final fully connected layer is used.\n",
        "    * The adaptive average pooling layer is removed in this case.\n",
        "\n",
        "The RNN and CNN model was experimented with, owing to findings from https://www.matec-conferences.org/articles/matecconf/pdf/2019/26/matecconf_jcmme2018_02001.pdf following a similar approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2ce6b727",
      "metadata": {
        "id": "2ce6b727"
      },
      "outputs": [],
      "source": [
        "rnn_cnn_model = rnn_cnn.CNNWithRNN(len(data.categories))\n",
        "torch.manual_seed(seed)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(rnn_cnn_model.parameters(), lr=4e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4dd9b270",
      "metadata": {
        "id": "4dd9b270",
        "outputId": "ad108e24-94b9-4727-d9f5-e37edf55a7ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch   0]: Training loss: 2.267701 | Accuracy: 0.180635\n",
            "[Epoch   0]: Validation loss: 2.187227 | Accuracy: 0.215556 | Within 3: 0.548889\n",
            "[Epoch   1]: Training loss: 1.861043 | Accuracy: 0.315873\n",
            "[Epoch   1]: Validation loss: 1.695775 | Accuracy: 0.368889 | Within 3: 0.700000\n",
            "[Epoch   2]: Training loss: 1.667541 | Accuracy: 0.401587\n",
            "[Epoch   2]: Validation loss: 1.628065 | Accuracy: 0.384444 | Within 3: 0.768889\n",
            "[Epoch   3]: Training loss: 1.530685 | Accuracy: 0.463492\n",
            "[Epoch   3]: Validation loss: 1.637616 | Accuracy: 0.384444 | Within 3: 0.726667\n",
            "[Epoch   4]: Training loss: 1.412013 | Accuracy: 0.506349\n",
            "[Epoch   4]: Validation loss: 1.464527 | Accuracy: 0.480000 | Within 3: 0.797778\n",
            "[Epoch   5]: Training loss: 1.299016 | Accuracy: 0.543492\n",
            "[Epoch   5]: Validation loss: 1.504222 | Accuracy: 0.442222 | Within 3: 0.764444\n",
            "[Epoch   6]: Training loss: 1.220570 | Accuracy: 0.569206\n",
            "[Epoch   6]: Validation loss: 1.291953 | Accuracy: 0.551111 | Within 3: 0.831111\n",
            "[Epoch   7]: Training loss: 1.151721 | Accuracy: 0.609206\n",
            "[Epoch   7]: Validation loss: 1.930485 | Accuracy: 0.402222 | Within 3: 0.715556\n",
            "[Epoch   8]: Training loss: 1.088983 | Accuracy: 0.627302\n",
            "[Epoch   8]: Validation loss: 1.345727 | Accuracy: 0.533333 | Within 3: 0.842222\n",
            "[Epoch   9]: Training loss: 1.033517 | Accuracy: 0.641270\n",
            "[Epoch   9]: Validation loss: 1.388131 | Accuracy: 0.566667 | Within 3: 0.837778\n",
            "[Epoch  10]: Training loss: 0.962159 | Accuracy: 0.663810\n",
            "[Epoch  10]: Validation loss: 1.473181 | Accuracy: 0.533333 | Within 3: 0.786667\n",
            "[Epoch  11]: Training loss: 0.894041 | Accuracy: 0.698730\n",
            "[Epoch  11]: Validation loss: 1.368866 | Accuracy: 0.582222 | Within 3: 0.848889\n",
            "[Epoch  12]: Training loss: 0.865153 | Accuracy: 0.710794\n",
            "[Epoch  12]: Validation loss: 1.508385 | Accuracy: 0.542222 | Within 3: 0.848889\n",
            "[Epoch  13]: Training loss: 0.777739 | Accuracy: 0.737143\n",
            "[Epoch  13]: Validation loss: 1.411547 | Accuracy: 0.617778 | Within 3: 0.844444\n",
            "[Epoch  14]: Training loss: 0.740714 | Accuracy: 0.745714\n",
            "[Epoch  14]: Validation loss: 1.448089 | Accuracy: 0.555556 | Within 3: 0.826667\n",
            "[Epoch  15]: Training loss: 0.677032 | Accuracy: 0.761905\n",
            "[Epoch  15]: Validation loss: 1.444462 | Accuracy: 0.588889 | Within 3: 0.842222\n",
            "[Epoch  16]: Training loss: 0.604514 | Accuracy: 0.795873\n",
            "[Epoch  16]: Validation loss: 1.269851 | Accuracy: 0.606667 | Within 3: 0.855556\n",
            "[Epoch  17]: Training loss: 0.556925 | Accuracy: 0.806032\n",
            "[Epoch  17]: Validation loss: 1.786191 | Accuracy: 0.506667 | Within 3: 0.804444\n",
            "[Epoch  18]: Training loss: 0.456945 | Accuracy: 0.843492\n",
            "[Epoch  18]: Validation loss: 1.433067 | Accuracy: 0.582222 | Within 3: 0.844444\n",
            "[Epoch  19]: Training loss: 0.408629 | Accuracy: 0.860000\n",
            "[Epoch  19]: Validation loss: 1.897093 | Accuracy: 0.571111 | Within 3: 0.828889\n",
            "[Epoch  20]: Training loss: 0.362043 | Accuracy: 0.884127\n",
            "[Epoch  20]: Validation loss: 1.570281 | Accuracy: 0.588889 | Within 3: 0.846667\n",
            "[Epoch  21]: Training loss: 0.296772 | Accuracy: 0.902222\n",
            "[Epoch  21]: Validation loss: 1.708306 | Accuracy: 0.613333 | Within 3: 0.840000\n",
            "[Epoch  22]: Training loss: 0.230484 | Accuracy: 0.928889\n",
            "[Epoch  22]: Validation loss: 1.566925 | Accuracy: 0.631111 | Within 3: 0.848889\n",
            "[Epoch  23]: Training loss: 0.205052 | Accuracy: 0.935873\n",
            "[Epoch  23]: Validation loss: 1.492299 | Accuracy: 0.655556 | Within 3: 0.873333\n",
            "[Epoch  24]: Training loss: 0.146249 | Accuracy: 0.954286\n",
            "[Epoch  24]: Validation loss: 1.537995 | Accuracy: 0.620000 | Within 3: 0.868889\n",
            "[Epoch  25]: Training loss: 0.138356 | Accuracy: 0.960317\n",
            "[Epoch  25]: Validation loss: 1.806990 | Accuracy: 0.635556 | Within 3: 0.866667\n",
            "[Epoch  26]: Training loss: 0.112917 | Accuracy: 0.970476\n",
            "[Epoch  26]: Validation loss: 3.018891 | Accuracy: 0.488889 | Within 3: 0.757778\n",
            "[Epoch  27]: Training loss: 0.089073 | Accuracy: 0.974921\n",
            "[Epoch  27]: Validation loss: 1.983309 | Accuracy: 0.608889 | Within 3: 0.855556\n",
            "[Epoch  28]: Training loss: 0.100229 | Accuracy: 0.974286\n",
            "[Epoch  28]: Validation loss: 2.099328 | Accuracy: 0.600000 | Within 3: 0.842222\n",
            "[Epoch  29]: Training loss: 0.066224 | Accuracy: 0.981587\n",
            "[Epoch  29]: Validation loss: 1.800480 | Accuracy: 0.644444 | Within 3: 0.877778\n",
            "Best epoch:  23\n"
          ]
        }
      ],
      "source": [
        "mtrainer = trainer.Trainer(rnn_cnn_model, optimizer, criterion, data, batch_size)\n",
        "mtrainer.run_train(num_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "89e50889",
      "metadata": {
        "id": "89e50889",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b976d96-fadf-4c7a-8bbd-8832720df4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 63.55555555555556 %\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc, top_k, incorect_stats = mtrainer.run_test(mtrainer.testloader, 3, True)\n",
        "print(f'Accuracy of the network on the test images: {test_acc*100} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65257700",
      "metadata": {
        "id": "65257700"
      },
      "source": [
        "* We can see that the RNN model did not do as well as our baseline model and in fact led to a small reduction in performance (63.5% < 64.5%).\n",
        "* In order to further understand this, we performed some paramter tuning on our model to see if that would affect our results, the results of which are explained below.\n",
        "\n",
        "* **Increase in patch size**:\n",
        "    * The increase in patch size led to a reduced performance on the RNN. This made sense since a larger patch size would require more information to be incorporated by the hidden cells and would lead to higher loss.\n",
        "* **More stacked layers**:\n",
        "    * Stacking multiple LSTM layers helped to increase the depth of our model and learn more features. We noticed that stacking 2 layers helped to provide a small improvement in the score, but increasing it to 3 led to a reduction. Thus stacking too many layers led to a higher degree of overfitting.\n",
        "* **Removing MaxPool after convolution**:\n",
        "    * An experiment was run with removing the MaxPool after the convolution layers as well, with the expectation that this would reduce abstraction and provide more data to the RNN. However this seemed to make performance worse as well. It would appear that the maxpool is important before applying the RNN.\n",
        "\n",
        "* The result obtained above is after identifying the best parameters from search."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "978cece1",
      "metadata": {
        "id": "978cece1"
      },
      "source": [
        "## Attention Neural Network (Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f59c7933",
      "metadata": {
        "id": "f59c7933"
      },
      "source": [
        "* In this approach, attention blocks are added after the convolution layers of the baseline model.\n",
        "* A custom attention layer is built which incorporates the following steps:\n",
        "    * An intermediate pooling result and the final pooled result are passed through convolutional layers.\n",
        "    * Following this, another convolutional layer is applied to reduce the number of channels to 1.\n",
        "    * A softmax is applied and multiplied with the intermdiate pooling result to get the attention elements.\n",
        "    \n",
        "The Attention with CNN model was experimented with, owing to findings from https://blog.paperspace.com/image-classification-with-attention/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2042725a",
      "metadata": {
        "id": "2042725a"
      },
      "outputs": [],
      "source": [
        "attention_cnn_model = attention_cnn.CNNWithAttention(len(data.categories))\n",
        "torch.manual_seed(seed)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(attention_cnn_model.parameters(), lr=4e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7d562685",
      "metadata": {
        "id": "7d562685",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8aa573-45b9-46f0-cdae-6247b2162c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch   0]: Training loss: 1.768142 | Accuracy: 0.369841\n",
            "[Epoch   0]: Validation loss: 1.673710 | Accuracy: 0.411111 | Within 3: 0.746667\n",
            "[Epoch   1]: Training loss: 1.598776 | Accuracy: 0.454603\n",
            "[Epoch   1]: Validation loss: 1.725220 | Accuracy: 0.415556 | Within 3: 0.724444\n",
            "[Epoch   2]: Training loss: 1.478499 | Accuracy: 0.501270\n",
            "[Epoch   2]: Validation loss: 1.664003 | Accuracy: 0.426667 | Within 3: 0.715556\n",
            "[Epoch   3]: Training loss: 1.395520 | Accuracy: 0.533016\n",
            "[Epoch   3]: Validation loss: 1.721746 | Accuracy: 0.415556 | Within 3: 0.700000\n",
            "[Epoch   4]: Training loss: 1.326853 | Accuracy: 0.539048\n",
            "[Epoch   4]: Validation loss: 1.404146 | Accuracy: 0.531111 | Within 3: 0.824444\n",
            "[Epoch   5]: Training loss: 1.244080 | Accuracy: 0.576508\n",
            "[Epoch   5]: Validation loss: 1.361586 | Accuracy: 0.500000 | Within 3: 0.815556\n",
            "[Epoch   6]: Training loss: 1.194026 | Accuracy: 0.593333\n",
            "[Epoch   6]: Validation loss: 1.369494 | Accuracy: 0.537778 | Within 3: 0.826667\n",
            "[Epoch   7]: Training loss: 1.145831 | Accuracy: 0.617143\n",
            "[Epoch   7]: Validation loss: 1.385464 | Accuracy: 0.540000 | Within 3: 0.820000\n",
            "[Epoch   8]: Training loss: 1.087339 | Accuracy: 0.632698\n",
            "[Epoch   8]: Validation loss: 1.341570 | Accuracy: 0.555556 | Within 3: 0.828889\n",
            "[Epoch   9]: Training loss: 1.014480 | Accuracy: 0.657143\n",
            "[Epoch   9]: Validation loss: 1.314315 | Accuracy: 0.580000 | Within 3: 0.860000\n",
            "[Epoch  10]: Training loss: 0.996827 | Accuracy: 0.660952\n",
            "[Epoch  10]: Validation loss: 1.243207 | Accuracy: 0.580000 | Within 3: 0.848889\n",
            "[Epoch  11]: Training loss: 0.934538 | Accuracy: 0.685079\n",
            "[Epoch  11]: Validation loss: 1.355860 | Accuracy: 0.555556 | Within 3: 0.842222\n",
            "[Epoch  12]: Training loss: 0.888702 | Accuracy: 0.706032\n",
            "[Epoch  12]: Validation loss: 1.455093 | Accuracy: 0.531111 | Within 3: 0.842222\n",
            "[Epoch  13]: Training loss: 0.865945 | Accuracy: 0.705079\n",
            "[Epoch  13]: Validation loss: 1.390618 | Accuracy: 0.582222 | Within 3: 0.848889\n",
            "[Epoch  14]: Training loss: 0.798145 | Accuracy: 0.731746\n",
            "[Epoch  14]: Validation loss: 1.141622 | Accuracy: 0.591111 | Within 3: 0.866667\n",
            "[Epoch  15]: Training loss: 0.717898 | Accuracy: 0.755238\n",
            "[Epoch  15]: Validation loss: 1.211970 | Accuracy: 0.617778 | Within 3: 0.875556\n",
            "[Epoch  16]: Training loss: 0.671330 | Accuracy: 0.776825\n",
            "[Epoch  16]: Validation loss: 1.110932 | Accuracy: 0.648889 | Within 3: 0.864444\n",
            "[Epoch  17]: Training loss: 0.649234 | Accuracy: 0.796508\n",
            "[Epoch  17]: Validation loss: 1.353965 | Accuracy: 0.571111 | Within 3: 0.837778\n",
            "[Epoch  18]: Training loss: 0.587495 | Accuracy: 0.814286\n",
            "[Epoch  18]: Validation loss: 1.238164 | Accuracy: 0.608889 | Within 3: 0.848889\n",
            "[Epoch  19]: Training loss: 0.531055 | Accuracy: 0.827302\n",
            "[Epoch  19]: Validation loss: 1.280557 | Accuracy: 0.582222 | Within 3: 0.853333\n",
            "[Epoch  20]: Training loss: 0.491722 | Accuracy: 0.835238\n",
            "[Epoch  20]: Validation loss: 1.377971 | Accuracy: 0.562222 | Within 3: 0.862222\n",
            "[Epoch  21]: Training loss: 0.484692 | Accuracy: 0.843175\n",
            "[Epoch  21]: Validation loss: 1.476613 | Accuracy: 0.573333 | Within 3: 0.860000\n",
            "[Epoch  22]: Training loss: 0.391982 | Accuracy: 0.878413\n",
            "[Epoch  22]: Validation loss: 1.242557 | Accuracy: 0.628889 | Within 3: 0.864444\n",
            "[Epoch  23]: Training loss: 0.365504 | Accuracy: 0.889841\n",
            "[Epoch  23]: Validation loss: 1.402276 | Accuracy: 0.557778 | Within 3: 0.837778\n",
            "[Epoch  24]: Training loss: 0.300985 | Accuracy: 0.911111\n",
            "[Epoch  24]: Validation loss: 1.258361 | Accuracy: 0.624444 | Within 3: 0.857778\n",
            "[Epoch  25]: Training loss: 0.332118 | Accuracy: 0.900000\n",
            "[Epoch  25]: Validation loss: 1.344076 | Accuracy: 0.617778 | Within 3: 0.866667\n",
            "[Epoch  26]: Training loss: 0.241973 | Accuracy: 0.932381\n",
            "[Epoch  26]: Validation loss: 1.266398 | Accuracy: 0.631111 | Within 3: 0.893333\n",
            "[Epoch  27]: Training loss: 0.220647 | Accuracy: 0.940317\n",
            "[Epoch  27]: Validation loss: 1.326414 | Accuracy: 0.648889 | Within 3: 0.860000\n",
            "[Epoch  28]: Training loss: 0.230885 | Accuracy: 0.933016\n",
            "[Epoch  28]: Validation loss: 1.439272 | Accuracy: 0.573333 | Within 3: 0.846667\n",
            "[Epoch  29]: Training loss: 0.177394 | Accuracy: 0.956508\n",
            "[Epoch  29]: Validation loss: 1.233052 | Accuracy: 0.666667 | Within 3: 0.871111\n",
            "Best epoch:  29\n"
          ]
        }
      ],
      "source": [
        "mtrainer = trainer.Trainer(attention_cnn_model, optimizer, criterion, data, batch_size)\n",
        "mtrainer.run_train(num_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6ee7ad66",
      "metadata": {
        "id": "6ee7ad66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a57d59-5e7a-4944-8ab7-6136d2e28933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 64.44444444444444 %\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc, top_k, incorect_stats = mtrainer.run_test(mtrainer.testloader, 3, True)\n",
        "print(f'Accuracy of the network on the test images: {test_acc*100} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05cb6639",
      "metadata": {
        "id": "05cb6639"
      },
      "source": [
        "* We can see that the Attention network almost performs as good as the baseline on the test set (64.4% ~ 64.5%).\n",
        "* With the potential for improved performance, we also aim to run our attention layers along with the residual CNN model, which incorporates skip connections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4d31df1b",
      "metadata": {
        "id": "4d31df1b"
      },
      "outputs": [],
      "source": [
        "attention_res_cnn_model = attention_cnn.ResidualCNNWithAttention(len(data.categories))\n",
        "torch.manual_seed(seed)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(attention_res_cnn_model.parameters(), lr=4e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a3de5c30",
      "metadata": {
        "id": "a3de5c30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b9a516d-3466-462d-a554-c0279db50982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch   0]: Training loss: 1.740546 | Accuracy: 0.373333\n",
            "[Epoch   0]: Validation loss: 1.817767 | Accuracy: 0.373333 | Within 3: 0.682222\n",
            "[Epoch   1]: Training loss: 1.545137 | Accuracy: 0.453651\n",
            "[Epoch   1]: Validation loss: 2.509645 | Accuracy: 0.257778 | Within 3: 0.568889\n",
            "[Epoch   2]: Training loss: 1.410294 | Accuracy: 0.506984\n",
            "[Epoch   2]: Validation loss: 1.528536 | Accuracy: 0.480000 | Within 3: 0.780000\n",
            "[Epoch   3]: Training loss: 1.331555 | Accuracy: 0.544762\n",
            "[Epoch   3]: Validation loss: 1.616146 | Accuracy: 0.431111 | Within 3: 0.728889\n",
            "[Epoch   4]: Training loss: 1.248188 | Accuracy: 0.566032\n",
            "[Epoch   4]: Validation loss: 1.397544 | Accuracy: 0.533333 | Within 3: 0.806667\n",
            "[Epoch   5]: Training loss: 1.192342 | Accuracy: 0.588254\n",
            "[Epoch   5]: Validation loss: 1.352943 | Accuracy: 0.546667 | Within 3: 0.797778\n",
            "[Epoch   6]: Training loss: 1.136594 | Accuracy: 0.604127\n",
            "[Epoch   6]: Validation loss: 1.549593 | Accuracy: 0.504444 | Within 3: 0.813333\n",
            "[Epoch   7]: Training loss: 1.050798 | Accuracy: 0.640000\n",
            "[Epoch   7]: Validation loss: 1.402220 | Accuracy: 0.560000 | Within 3: 0.793333\n",
            "[Epoch   8]: Training loss: 1.026631 | Accuracy: 0.649841\n",
            "[Epoch   8]: Validation loss: 1.435103 | Accuracy: 0.535556 | Within 3: 0.837778\n",
            "[Epoch   9]: Training loss: 0.964038 | Accuracy: 0.666667\n",
            "[Epoch   9]: Validation loss: 2.112292 | Accuracy: 0.444444 | Within 3: 0.717778\n",
            "[Epoch  10]: Training loss: 0.905927 | Accuracy: 0.689206\n",
            "[Epoch  10]: Validation loss: 1.289615 | Accuracy: 0.577778 | Within 3: 0.840000\n",
            "[Epoch  11]: Training loss: 0.832243 | Accuracy: 0.719683\n",
            "[Epoch  11]: Validation loss: 1.451493 | Accuracy: 0.555556 | Within 3: 0.813333\n",
            "[Epoch  12]: Training loss: 0.804558 | Accuracy: 0.726032\n",
            "[Epoch  12]: Validation loss: 1.376358 | Accuracy: 0.553333 | Within 3: 0.826667\n",
            "[Epoch  13]: Training loss: 0.743691 | Accuracy: 0.738095\n",
            "[Epoch  13]: Validation loss: 1.691422 | Accuracy: 0.484444 | Within 3: 0.808889\n",
            "[Epoch  14]: Training loss: 0.690370 | Accuracy: 0.760635\n",
            "[Epoch  14]: Validation loss: 1.467238 | Accuracy: 0.497778 | Within 3: 0.795556\n",
            "[Epoch  15]: Training loss: 0.651133 | Accuracy: 0.779683\n",
            "[Epoch  15]: Validation loss: 1.778160 | Accuracy: 0.542222 | Within 3: 0.791111\n",
            "[Epoch  16]: Training loss: 0.608280 | Accuracy: 0.791746\n",
            "[Epoch  16]: Validation loss: 1.233220 | Accuracy: 0.620000 | Within 3: 0.857778\n",
            "[Epoch  17]: Training loss: 0.548263 | Accuracy: 0.815873\n",
            "[Epoch  17]: Validation loss: 1.719099 | Accuracy: 0.548889 | Within 3: 0.806667\n",
            "[Epoch  18]: Training loss: 0.493488 | Accuracy: 0.834286\n",
            "[Epoch  18]: Validation loss: 1.430006 | Accuracy: 0.573333 | Within 3: 0.853333\n",
            "[Epoch  19]: Training loss: 0.433628 | Accuracy: 0.856508\n",
            "[Epoch  19]: Validation loss: 1.508848 | Accuracy: 0.631111 | Within 3: 0.875556\n",
            "[Epoch  20]: Training loss: 0.412667 | Accuracy: 0.865714\n",
            "[Epoch  20]: Validation loss: 1.429053 | Accuracy: 0.608889 | Within 3: 0.833333\n",
            "[Epoch  21]: Training loss: 0.334219 | Accuracy: 0.892698\n",
            "[Epoch  21]: Validation loss: 1.449615 | Accuracy: 0.577778 | Within 3: 0.846667\n",
            "[Epoch  22]: Training loss: 0.326619 | Accuracy: 0.894921\n",
            "[Epoch  22]: Validation loss: 1.518344 | Accuracy: 0.588889 | Within 3: 0.871111\n",
            "[Epoch  23]: Training loss: 0.264764 | Accuracy: 0.914921\n",
            "[Epoch  23]: Validation loss: 1.219869 | Accuracy: 0.640000 | Within 3: 0.868889\n",
            "[Epoch  24]: Training loss: 0.227004 | Accuracy: 0.933968\n",
            "[Epoch  24]: Validation loss: 1.210579 | Accuracy: 0.664444 | Within 3: 0.866667\n",
            "[Epoch  25]: Training loss: 0.278100 | Accuracy: 0.913333\n",
            "[Epoch  25]: Validation loss: 1.803047 | Accuracy: 0.582222 | Within 3: 0.831111\n",
            "[Epoch  26]: Training loss: 0.196318 | Accuracy: 0.940952\n",
            "[Epoch  26]: Validation loss: 1.464823 | Accuracy: 0.651111 | Within 3: 0.864444\n",
            "[Epoch  27]: Training loss: 0.157184 | Accuracy: 0.959365\n",
            "[Epoch  27]: Validation loss: 1.494472 | Accuracy: 0.628889 | Within 3: 0.862222\n",
            "[Epoch  28]: Training loss: 0.160479 | Accuracy: 0.958413\n",
            "[Epoch  28]: Validation loss: 1.496205 | Accuracy: 0.644444 | Within 3: 0.853333\n",
            "[Epoch  29]: Training loss: 0.157896 | Accuracy: 0.956508\n",
            "[Epoch  29]: Validation loss: 1.235843 | Accuracy: 0.684444 | Within 3: 0.877778\n",
            "Best epoch:  29\n"
          ]
        }
      ],
      "source": [
        "mtrainer = trainer.Trainer(attention_res_cnn_model, optimizer, criterion, data, batch_size)\n",
        "mtrainer.run_train(num_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0f334253",
      "metadata": {
        "id": "0f334253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc662ad-e056-40a7-d80b-9ae052790882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 63.888888888888886 %\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc, top_k, incorect_stats = mtrainer.run_test(mtrainer.testloader, 3, True)\n",
        "print(f'Accuracy of the network on the test images: {test_acc*100} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* It's surprising to see that attention on the residual network performs slightly worse than attention on the baseline (63.8% < 64.4%).\n",
        "* However, this is an improvement over the score obtained on the RNN layer.\n",
        "* We continue trying a further improvement of having a convolutional based attention layer.\n"
      ],
      "metadata": {
        "id": "cFeImun8ziBA"
      },
      "id": "cFeImun8ziBA"
    },
    {
      "cell_type": "code",
      "source": [
        "attention_res_conv_cnn_model = attention_cnn.CNNWithConvAttention(len(data.categories))\n",
        "torch.manual_seed(seed)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(attention_res_conv_cnn_model.parameters(), lr=4e-4)"
      ],
      "metadata": {
        "id": "859ExaHNzfYx"
      },
      "id": "859ExaHNzfYx",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mtrainer = trainer.Trainer(attention_res_conv_cnn_model, optimizer, criterion, data, batch_size)\n",
        "mtrainer.run_train(num_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4mTGO_P0Pce",
        "outputId": "059f23b6-5b0b-4e0b-cebf-97d6e2b56e1d"
      },
      "id": "X4mTGO_P0Pce",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch   0]: Training loss: 1.733191 | Accuracy: 0.388571\n",
            "[Epoch   0]: Validation loss: 1.620318 | Accuracy: 0.440000 | Within 3: 0.744444\n",
            "[Epoch   1]: Training loss: 1.541552 | Accuracy: 0.458413\n",
            "[Epoch   1]: Validation loss: 1.573415 | Accuracy: 0.440000 | Within 3: 0.768889\n",
            "[Epoch   2]: Training loss: 1.411207 | Accuracy: 0.523810\n",
            "[Epoch   2]: Validation loss: 1.560676 | Accuracy: 0.464444 | Within 3: 0.728889\n",
            "[Epoch   3]: Training loss: 1.336674 | Accuracy: 0.539365\n",
            "[Epoch   3]: Validation loss: 1.459053 | Accuracy: 0.482222 | Within 3: 0.800000\n",
            "[Epoch   4]: Training loss: 1.249114 | Accuracy: 0.572698\n",
            "[Epoch   4]: Validation loss: 1.942010 | Accuracy: 0.380000 | Within 3: 0.740000\n",
            "[Epoch   5]: Training loss: 1.162595 | Accuracy: 0.607619\n",
            "[Epoch   5]: Validation loss: 1.456341 | Accuracy: 0.484444 | Within 3: 0.802222\n",
            "[Epoch   6]: Training loss: 1.106963 | Accuracy: 0.633016\n",
            "[Epoch   6]: Validation loss: 1.419516 | Accuracy: 0.544444 | Within 3: 0.793333\n",
            "[Epoch   7]: Training loss: 1.037960 | Accuracy: 0.658730\n",
            "[Epoch   7]: Validation loss: 1.279327 | Accuracy: 0.580000 | Within 3: 0.846667\n",
            "[Epoch   8]: Training loss: 0.966012 | Accuracy: 0.687937\n",
            "[Epoch   8]: Validation loss: 1.280972 | Accuracy: 0.584444 | Within 3: 0.868889\n",
            "[Epoch   9]: Training loss: 0.894733 | Accuracy: 0.697143\n",
            "[Epoch   9]: Validation loss: 1.317695 | Accuracy: 0.606667 | Within 3: 0.846667\n",
            "[Epoch  10]: Training loss: 0.826775 | Accuracy: 0.734286\n",
            "[Epoch  10]: Validation loss: 1.328210 | Accuracy: 0.604444 | Within 3: 0.857778\n",
            "[Epoch  11]: Training loss: 0.764348 | Accuracy: 0.755238\n",
            "[Epoch  11]: Validation loss: 1.337776 | Accuracy: 0.608889 | Within 3: 0.848889\n",
            "[Epoch  12]: Training loss: 0.705107 | Accuracy: 0.778095\n",
            "[Epoch  12]: Validation loss: 1.512133 | Accuracy: 0.555556 | Within 3: 0.835556\n",
            "[Epoch  13]: Training loss: 0.634395 | Accuracy: 0.802222\n",
            "[Epoch  13]: Validation loss: 1.448844 | Accuracy: 0.571111 | Within 3: 0.844444\n",
            "[Epoch  14]: Training loss: 0.555777 | Accuracy: 0.827937\n",
            "[Epoch  14]: Validation loss: 1.215201 | Accuracy: 0.626667 | Within 3: 0.884444\n",
            "[Epoch  15]: Training loss: 0.480233 | Accuracy: 0.853651\n",
            "[Epoch  15]: Validation loss: 1.468280 | Accuracy: 0.566667 | Within 3: 0.835556\n",
            "[Epoch  16]: Training loss: 0.424843 | Accuracy: 0.880000\n",
            "[Epoch  16]: Validation loss: 1.332965 | Accuracy: 0.580000 | Within 3: 0.837778\n",
            "[Epoch  17]: Training loss: 0.356419 | Accuracy: 0.901905\n",
            "[Epoch  17]: Validation loss: 1.388772 | Accuracy: 0.608889 | Within 3: 0.871111\n",
            "[Epoch  18]: Training loss: 0.292436 | Accuracy: 0.922857\n",
            "[Epoch  18]: Validation loss: 1.232802 | Accuracy: 0.615556 | Within 3: 0.853333\n",
            "[Epoch  19]: Training loss: 0.219540 | Accuracy: 0.954286\n",
            "[Epoch  19]: Validation loss: 1.769987 | Accuracy: 0.615556 | Within 3: 0.860000\n",
            "[Epoch  20]: Training loss: 0.178822 | Accuracy: 0.968254\n",
            "[Epoch  20]: Validation loss: 1.147258 | Accuracy: 0.646667 | Within 3: 0.902222\n",
            "[Epoch  21]: Training loss: 0.143575 | Accuracy: 0.979048\n",
            "[Epoch  21]: Validation loss: 1.398456 | Accuracy: 0.591111 | Within 3: 0.873333\n",
            "[Epoch  22]: Training loss: 0.115992 | Accuracy: 0.983175\n",
            "[Epoch  22]: Validation loss: 1.100205 | Accuracy: 0.662222 | Within 3: 0.893333\n",
            "[Epoch  23]: Training loss: 0.087266 | Accuracy: 0.987937\n",
            "[Epoch  23]: Validation loss: 1.066552 | Accuracy: 0.675556 | Within 3: 0.900000\n",
            "[Epoch  24]: Training loss: 0.074771 | Accuracy: 0.991111\n",
            "[Epoch  24]: Validation loss: 1.206444 | Accuracy: 0.657778 | Within 3: 0.873333\n",
            "[Epoch  25]: Training loss: 0.076818 | Accuracy: 0.988889\n",
            "[Epoch  25]: Validation loss: 1.139863 | Accuracy: 0.686667 | Within 3: 0.893333\n",
            "[Epoch  26]: Training loss: 0.084873 | Accuracy: 0.986667\n",
            "[Epoch  26]: Validation loss: 1.348579 | Accuracy: 0.651111 | Within 3: 0.882222\n",
            "[Epoch  27]: Training loss: 0.123427 | Accuracy: 0.972381\n",
            "[Epoch  27]: Validation loss: 1.682629 | Accuracy: 0.613333 | Within 3: 0.862222\n",
            "[Epoch  28]: Training loss: 0.092573 | Accuracy: 0.983175\n",
            "[Epoch  28]: Validation loss: 1.419036 | Accuracy: 0.620000 | Within 3: 0.864444\n",
            "[Epoch  29]: Training loss: 0.051063 | Accuracy: 0.994603\n",
            "[Epoch  29]: Validation loss: 1.041536 | Accuracy: 0.700000 | Within 3: 0.886667\n",
            "Best epoch:  29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc, top_k, incorect_stats = mtrainer.run_test(mtrainer.testloader, 3, True)\n",
        "print(f'Accuracy of the network on the test images: {test_acc*100} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePxmoP_T0SCR",
        "outputId": "713159e5-bbb1-4c48-e43e-08b4e34f4e3d"
      },
      "id": "ePxmoP_T0SCR",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 67.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The ConvAttention module seems to have given the best performance with a significant improvement over the baseline (67% > 64.5%).\n",
        "* We can thus see that attention can be helpful in image classification."
      ],
      "metadata": {
        "id": "P-EMEwqs2dKw"
      },
      "id": "P-EMEwqs2dKw"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}