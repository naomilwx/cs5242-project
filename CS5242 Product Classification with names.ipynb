{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53e22fb",
   "metadata": {},
   "source": [
    "# Shopee Product Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b4f80",
   "metadata": {},
   "source": [
    "Notebook to experiment over several Neural Networks over the product dataset obtained from Shopee and evaluate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa5624",
   "metadata": {},
   "source": [
    "The following models are evaluated as part of this notebook:\n",
    "\n",
    "Baseline 1: CNN <br>\n",
    "Baseline 2: CNN with augmented layers <br>\n",
    "Improvement 1: Adding RNN <br>\n",
    "Improvement 2: Adding attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e52a97",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97c7e4bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (0.19.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from scikit-image) (1.7.1)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from scikit-image) (2.6.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from scikit-image) (2021.11.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from scikit-image) (21.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from scikit-image) (1.21.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from scikit-image) (2.22.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from scikit-image) (8.4.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from packaging>=20.0->scikit-image) (2.4.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 22.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shopee_crawler in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (0.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 22.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.3; however, version 22.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from torchvision) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: torch==1.12.1 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from torchvision) (1.21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (4.6.0.66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 22.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\shubh\\.pyenv\\pyenv-win\\versions\\3.7.9\\lib\\site-packages (from opencv-python) (1.21.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image\n",
    "!pip install shopee_crawler\n",
    "!pip install torchvision\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7320f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887334e",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a686c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.text import dataset\n",
    "from model.dataset import all_categories\n",
    "from scripts.crawler import product_category_and_names\n",
    "\n",
    "_, product_names = product_category_and_names('data')\n",
    "\n",
    "data = dataset.DataSet(product_names, max_num_img=300, categories=all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712aabfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 313.87it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 351.39it/s]\n",
      "100%|██████████| 300/300 [00:01<00:00, 283.74it/s]\n",
      "100%|██████████| 300/300 [00:01<00:00, 274.48it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 309.64it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 304.33it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 301.51it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 390.06it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 392.24it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 357.95it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 345.52it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 408.94it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 349.00it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 333.14it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 403.32it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 356.31it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 396.48it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 397.07it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 370.10it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 369.43it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 388.73it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 409.46it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 367.14it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 352.81it/s]\n"
     ]
    }
   ],
   "source": [
    "data.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d192805",
   "metadata": {},
   "source": [
    "## CNN Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e3ef77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.text import trainer, baseline\n",
    "\n",
    "batch_size = 32\n",
    "datastore = trainer.DataStore(data, batch_size)\n",
    "\n",
    "baseline_model = baseline.BaselineCNN(len(data.categories), datastore.vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=5e-4)\n",
    "mtrainer = trainer.Trainer(baseline_model, optimizer, criterion, batch_size, datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aff205c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model.text.baseline' from '/Users/naomileow/Documents/school/CS5242/project/model/text/baseline.py'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(trainer)\n",
    "importlib.reload(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d89ba372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0 |   100 batches loss: 2.9703\n",
      "[Epoch   0]: Training loss: 2.930701 | Accuracy: 0.140278\n",
      "[Epoch   0]: Validation loss: 2.862117 | Accuracy: 0.162500 | Within 3: 0.358333\n",
      "epoch   1 |   100 batches loss: 2.8030\n",
      "[Epoch   1]: Training loss: 2.764578 | Accuracy: 0.195635\n",
      "[Epoch   1]: Validation loss: 2.782124 | Accuracy: 0.191667 | Within 3: 0.402778\n",
      "epoch   2 |   100 batches loss: 2.6021\n",
      "[Epoch   2]: Training loss: 2.567240 | Accuracy: 0.267262\n",
      "[Epoch   2]: Validation loss: 2.490155 | Accuracy: 0.290278 | Within 3: 0.512500\n",
      "epoch   3 |   100 batches loss: 2.3259\n",
      "[Epoch   3]: Training loss: 2.293586 | Accuracy: 0.359524\n",
      "[Epoch   3]: Validation loss: 2.230767 | Accuracy: 0.387500 | Within 3: 0.593056\n",
      "epoch   4 |   100 batches loss: 2.0362\n",
      "[Epoch   4]: Training loss: 2.005825 | Accuracy: 0.445635\n",
      "[Epoch   4]: Validation loss: 2.043289 | Accuracy: 0.415278 | Within 3: 0.645833\n",
      "epoch   5 |   100 batches loss: 1.7803\n",
      "[Epoch   5]: Training loss: 1.771212 | Accuracy: 0.505159\n",
      "[Epoch   5]: Validation loss: 1.938514 | Accuracy: 0.448611 | Within 3: 0.650000\n",
      "epoch   6 |   100 batches loss: 1.5736\n",
      "[Epoch   6]: Training loss: 1.575838 | Accuracy: 0.552579\n",
      "[Epoch   6]: Validation loss: 1.752473 | Accuracy: 0.513889 | Within 3: 0.715278\n",
      "epoch   7 |   100 batches loss: 1.4203\n",
      "[Epoch   7]: Training loss: 1.413105 | Accuracy: 0.605754\n",
      "[Epoch   7]: Validation loss: 1.664493 | Accuracy: 0.536111 | Within 3: 0.736111\n",
      "epoch   8 |   100 batches loss: 1.2600\n",
      "[Epoch   8]: Training loss: 1.267596 | Accuracy: 0.637897\n",
      "[Epoch   8]: Validation loss: 1.615323 | Accuracy: 0.552778 | Within 3: 0.747222\n",
      "epoch   9 |   100 batches loss: 1.1597\n",
      "[Epoch   9]: Training loss: 1.146856 | Accuracy: 0.681944\n",
      "[Epoch   9]: Validation loss: 1.609350 | Accuracy: 0.556944 | Within 3: 0.750000\n",
      "epoch  10 |   100 batches loss: 1.0272\n",
      "[Epoch  10]: Training loss: 1.032666 | Accuracy: 0.718849\n",
      "[Epoch  10]: Validation loss: 1.574500 | Accuracy: 0.569444 | Within 3: 0.765278\n",
      "epoch  11 |   100 batches loss: 0.9292\n",
      "[Epoch  11]: Training loss: 0.939811 | Accuracy: 0.742659\n",
      "[Epoch  11]: Validation loss: 1.526499 | Accuracy: 0.579167 | Within 3: 0.777778\n",
      "epoch  12 |   100 batches loss: 0.8529\n",
      "[Epoch  12]: Training loss: 0.849368 | Accuracy: 0.768849\n",
      "[Epoch  12]: Validation loss: 1.489560 | Accuracy: 0.591667 | Within 3: 0.794444\n",
      "epoch  13 |   100 batches loss: 0.7864\n",
      "[Epoch  13]: Training loss: 0.771297 | Accuracy: 0.792460\n",
      "[Epoch  13]: Validation loss: 1.494801 | Accuracy: 0.601389 | Within 3: 0.798611\n",
      "epoch  14 |   100 batches loss: 0.6952\n",
      "[Epoch  14]: Training loss: 0.700272 | Accuracy: 0.817659\n",
      "[Epoch  14]: Validation loss: 1.488297 | Accuracy: 0.606944 | Within 3: 0.798611\n",
      "epoch  15 |   100 batches loss: 0.6258\n",
      "[Epoch  15]: Training loss: 0.635441 | Accuracy: 0.835516\n",
      "[Epoch  15]: Validation loss: 1.514011 | Accuracy: 0.612500 | Within 3: 0.786111\n",
      "epoch  16 |   100 batches loss: 0.5799\n",
      "[Epoch  16]: Training loss: 0.573745 | Accuracy: 0.850000\n",
      "[Epoch  16]: Validation loss: 1.469703 | Accuracy: 0.613889 | Within 3: 0.805556\n",
      "epoch  17 |   100 batches loss: 0.5179\n",
      "[Epoch  17]: Training loss: 0.518031 | Accuracy: 0.868849\n",
      "[Epoch  17]: Validation loss: 1.481194 | Accuracy: 0.626389 | Within 3: 0.805556\n",
      "epoch  18 |   100 batches loss: 0.4673\n",
      "[Epoch  18]: Training loss: 0.469360 | Accuracy: 0.884921\n",
      "[Epoch  18]: Validation loss: 1.550503 | Accuracy: 0.612500 | Within 3: 0.802778\n",
      "epoch  19 |   100 batches loss: 0.4399\n",
      "[Epoch  19]: Training loss: 0.423112 | Accuracy: 0.896429\n",
      "[Epoch  19]: Validation loss: 1.542781 | Accuracy: 0.629167 | Within 3: 0.822222\n",
      "epoch  20 |   100 batches loss: 0.3676\n",
      "[Epoch  20]: Training loss: 0.379603 | Accuracy: 0.908333\n",
      "[Epoch  20]: Validation loss: 1.548012 | Accuracy: 0.627778 | Within 3: 0.809722\n",
      "epoch  21 |   100 batches loss: 0.3304\n",
      "[Epoch  21]: Training loss: 0.336413 | Accuracy: 0.923214\n",
      "[Epoch  21]: Validation loss: 1.556825 | Accuracy: 0.638889 | Within 3: 0.806944\n",
      "epoch  22 |   100 batches loss: 0.2926\n",
      "[Epoch  22]: Training loss: 0.302129 | Accuracy: 0.930159\n",
      "[Epoch  22]: Validation loss: 1.554542 | Accuracy: 0.638889 | Within 3: 0.818056\n",
      "epoch  23 |   100 batches loss: 0.2707\n",
      "[Epoch  23]: Training loss: 0.268356 | Accuracy: 0.943651\n",
      "[Epoch  23]: Validation loss: 1.562224 | Accuracy: 0.633333 | Within 3: 0.812500\n",
      "epoch  24 |   100 batches loss: 0.2303\n",
      "[Epoch  24]: Training loss: 0.235660 | Accuracy: 0.953175\n",
      "[Epoch  24]: Validation loss: 1.604356 | Accuracy: 0.647222 | Within 3: 0.811111\n",
      "epoch  25 |   100 batches loss: 0.2044\n",
      "[Epoch  25]: Training loss: 0.203625 | Accuracy: 0.958929\n",
      "[Epoch  25]: Validation loss: 1.644425 | Accuracy: 0.643056 | Within 3: 0.813889\n",
      "epoch  26 |   100 batches loss: 0.1764\n",
      "[Epoch  26]: Training loss: 0.179608 | Accuracy: 0.969444\n",
      "[Epoch  26]: Validation loss: 1.605759 | Accuracy: 0.658333 | Within 3: 0.826389\n",
      "epoch  27 |   100 batches loss: 0.1502\n",
      "[Epoch  27]: Training loss: 0.154338 | Accuracy: 0.974802\n",
      "[Epoch  27]: Validation loss: 1.719883 | Accuracy: 0.630556 | Within 3: 0.813889\n",
      "epoch  28 |   100 batches loss: 0.1260\n",
      "[Epoch  28]: Training loss: 0.128640 | Accuracy: 0.981944\n",
      "[Epoch  28]: Validation loss: 1.659763 | Accuracy: 0.650000 | Within 3: 0.825000\n",
      "epoch  29 |   100 batches loss: 0.1126\n",
      "[Epoch  29]: Training loss: 0.112554 | Accuracy: 0.985119\n",
      "[Epoch  29]: Validation loss: 1.741540 | Accuracy: 0.638889 | Within 3: 0.813889\n",
      "Best epoch:  26\n"
     ]
    }
   ],
   "source": [
    "mtrainer.run_train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8c903eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 60.416666666666664 %\n",
      "Accuracy within top 3 results: 80.20833333333334 %\n",
      "(Women's-Shoes, Men's-Shoes): 20\n",
      "(Women's-Bags, Men's-Bags): 17\n",
      "(Home-Appliances, Pet-Food-Supplies): 15\n",
      "(Home-Living, Toys-Kids-Babies): 14\n",
      "(Beauty-Personal-Care, Pet-Food-Supplies): 12\n",
      "(Women's-Apparel, Men's-Wear): 10\n",
      "(Travel-Luggage, Women's-Bags): 9\n",
      "(Food-Beverages, Pet-Food-Supplies): 8\n",
      "(Mobile-Gadgets, Watches): 8\n",
      "(Men's-Shoes, Women's-Shoes): 8\n",
      "(Toys-Kids-Babies, Pet-Food-Supplies): 8\n",
      "(Computers-Peripherals, Pet-Food-Supplies): 7\n",
      "(Hobbies-Books, Toys-Kids-Babies): 7\n",
      "(Hobbies-Books, Pet-Food-Supplies): 7\n",
      "(Home-Living, Pet-Food-Supplies): 6\n",
      "(Kids-Fashion, Toys-Kids-Babies): 6\n",
      "(Home-Living, Hobbies-Books): 6\n",
      "(Toys-Kids-Babies, Hobbies-Books): 6\n",
      "(Beauty-Personal-Care, Toys-Kids-Babies): 6\n",
      "(Home-Appliances, Toys-Kids-Babies): 6\n",
      "(Sports-Outdoors, Pet-Food-Supplies): 5\n",
      "(Kids-Fashion, Jewellery-Accessories): 5\n",
      "(Kids-Fashion, Sports-Outdoors): 5\n",
      "(Health-Wellness, Pet-Food-Supplies): 5\n",
      "(Beauty-Personal-Care, Food-Beverages): 5\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, top_k, incorect_stats = mtrainer.run_test(mtrainer.data.testloader, 3, True)\n",
    "print(f'Accuracy of the network on the test images: {test_acc*100} %')\n",
    "print(f'Accuracy within top 3 results: {top_k*100} %')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "counts = Counter(incorect_stats).most_common(25)\n",
    "for k, v in counts:\n",
    "    print(f\"({data.categories[k[0]]}, {data.categories[k[1]]}): {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb07411f",
   "metadata": {},
   "source": [
    "## Deeper CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5300ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.text import trainer, baseline\n",
    "\n",
    "batch_size = 32\n",
    "datastore = trainer.DataStore(data, batch_size)\n",
    "\n",
    "deeper_model = baseline.DeeperCNN(len(data.categories), datastore.vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(deeper_model.parameters(), lr=5e-4)\n",
    "mtrainer = trainer.Trainer(deeper_model, optimizer, criterion, batch_size, datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "193e80c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0 |   100 batches loss: 2.9945\n",
      "[Epoch   0]: Training loss: 2.964932 | Accuracy: 0.123611\n",
      "[Epoch   0]: Validation loss: 2.910496 | Accuracy: 0.123611 | Within 3: 0.312500\n",
      "epoch   1 |   100 batches loss: 2.8244\n",
      "[Epoch   1]: Training loss: 2.806816 | Accuracy: 0.176984\n",
      "[Epoch   1]: Validation loss: 2.726535 | Accuracy: 0.193056 | Within 3: 0.438889\n",
      "epoch   2 |   100 batches loss: 2.6274\n",
      "[Epoch   2]: Training loss: 2.590389 | Accuracy: 0.261508\n",
      "[Epoch   2]: Validation loss: 2.534928 | Accuracy: 0.270833 | Within 3: 0.509722\n",
      "epoch   3 |   100 batches loss: 2.3283\n",
      "[Epoch   3]: Training loss: 2.290451 | Accuracy: 0.356349\n",
      "[Epoch   3]: Validation loss: 2.273786 | Accuracy: 0.337500 | Within 3: 0.591667\n",
      "epoch   4 |   100 batches loss: 2.0392\n",
      "[Epoch   4]: Training loss: 2.015556 | Accuracy: 0.427976\n",
      "[Epoch   4]: Validation loss: 2.189071 | Accuracy: 0.370833 | Within 3: 0.623611\n",
      "epoch   5 |   100 batches loss: 1.8046\n",
      "[Epoch   5]: Training loss: 1.776633 | Accuracy: 0.497619\n",
      "[Epoch   5]: Validation loss: 2.022328 | Accuracy: 0.447222 | Within 3: 0.668056\n",
      "epoch   6 |   100 batches loss: 1.5938\n",
      "[Epoch   6]: Training loss: 1.584360 | Accuracy: 0.549206\n",
      "[Epoch   6]: Validation loss: 1.925660 | Accuracy: 0.483333 | Within 3: 0.687500\n",
      "epoch   7 |   100 batches loss: 1.4562\n",
      "[Epoch   7]: Training loss: 1.423060 | Accuracy: 0.600992\n",
      "[Epoch   7]: Validation loss: 1.890389 | Accuracy: 0.498611 | Within 3: 0.698611\n",
      "epoch   8 |   100 batches loss: 1.2989\n",
      "[Epoch   8]: Training loss: 1.279048 | Accuracy: 0.637897\n",
      "[Epoch   8]: Validation loss: 1.861225 | Accuracy: 0.493056 | Within 3: 0.713889\n",
      "epoch   9 |   100 batches loss: 1.1639\n",
      "[Epoch   9]: Training loss: 1.157859 | Accuracy: 0.666468\n",
      "[Epoch   9]: Validation loss: 1.798205 | Accuracy: 0.504167 | Within 3: 0.720833\n",
      "epoch  10 |   100 batches loss: 1.0585\n",
      "[Epoch  10]: Training loss: 1.045168 | Accuracy: 0.706349\n",
      "[Epoch  10]: Validation loss: 1.779673 | Accuracy: 0.512500 | Within 3: 0.733333\n",
      "epoch  11 |   100 batches loss: 0.9481\n",
      "[Epoch  11]: Training loss: 0.950465 | Accuracy: 0.735913\n",
      "[Epoch  11]: Validation loss: 1.747507 | Accuracy: 0.534722 | Within 3: 0.743056\n",
      "epoch  12 |   100 batches loss: 0.8378\n",
      "[Epoch  12]: Training loss: 0.861444 | Accuracy: 0.762897\n",
      "[Epoch  12]: Validation loss: 1.771562 | Accuracy: 0.533333 | Within 3: 0.737500\n",
      "epoch  13 |   100 batches loss: 0.7808\n",
      "[Epoch  13]: Training loss: 0.780761 | Accuracy: 0.789484\n",
      "[Epoch  13]: Validation loss: 1.807234 | Accuracy: 0.551389 | Within 3: 0.755556\n",
      "epoch  14 |   100 batches loss: 0.7120\n",
      "[Epoch  14]: Training loss: 0.710633 | Accuracy: 0.814286\n",
      "[Epoch  14]: Validation loss: 1.789558 | Accuracy: 0.543056 | Within 3: 0.752778\n",
      "epoch  15 |   100 batches loss: 0.6508\n",
      "[Epoch  15]: Training loss: 0.642519 | Accuracy: 0.828968\n",
      "[Epoch  15]: Validation loss: 1.784054 | Accuracy: 0.556944 | Within 3: 0.766667\n",
      "epoch  16 |   100 batches loss: 0.5837\n",
      "[Epoch  16]: Training loss: 0.583703 | Accuracy: 0.849603\n",
      "[Epoch  16]: Validation loss: 1.794487 | Accuracy: 0.540278 | Within 3: 0.768056\n",
      "epoch  17 |   100 batches loss: 0.5456\n",
      "[Epoch  17]: Training loss: 0.536307 | Accuracy: 0.862500\n",
      "[Epoch  17]: Validation loss: 1.831271 | Accuracy: 0.562500 | Within 3: 0.759722\n",
      "epoch  18 |   100 batches loss: 0.4987\n",
      "[Epoch  18]: Training loss: 0.492153 | Accuracy: 0.872024\n",
      "[Epoch  18]: Validation loss: 1.846596 | Accuracy: 0.561111 | Within 3: 0.759722\n",
      "epoch  19 |   100 batches loss: 0.4525\n",
      "[Epoch  19]: Training loss: 0.438901 | Accuracy: 0.889881\n",
      "[Epoch  19]: Validation loss: 1.828774 | Accuracy: 0.556944 | Within 3: 0.762500\n",
      "epoch  20 |   100 batches loss: 0.3888\n",
      "[Epoch  20]: Training loss: 0.402920 | Accuracy: 0.901984\n",
      "[Epoch  20]: Validation loss: 1.902763 | Accuracy: 0.568056 | Within 3: 0.763889\n",
      "epoch  21 |   100 batches loss: 0.3705\n",
      "[Epoch  21]: Training loss: 0.364398 | Accuracy: 0.913095\n",
      "[Epoch  21]: Validation loss: 1.870919 | Accuracy: 0.577778 | Within 3: 0.780556\n",
      "epoch  22 |   100 batches loss: 0.3331\n",
      "[Epoch  22]: Training loss: 0.331926 | Accuracy: 0.925992\n",
      "[Epoch  22]: Validation loss: 1.888593 | Accuracy: 0.572222 | Within 3: 0.773611\n",
      "epoch  23 |   100 batches loss: 0.3049\n",
      "[Epoch  23]: Training loss: 0.299353 | Accuracy: 0.933135\n",
      "[Epoch  23]: Validation loss: 1.902358 | Accuracy: 0.590278 | Within 3: 0.780556\n",
      "epoch  24 |   100 batches loss: 0.2546\n",
      "[Epoch  24]: Training loss: 0.268307 | Accuracy: 0.942063\n",
      "[Epoch  24]: Validation loss: 1.944817 | Accuracy: 0.583333 | Within 3: 0.779167\n",
      "epoch  25 |   100 batches loss: 0.2369\n",
      "[Epoch  25]: Training loss: 0.241833 | Accuracy: 0.951389\n",
      "[Epoch  25]: Validation loss: 2.000357 | Accuracy: 0.590278 | Within 3: 0.779167\n",
      "epoch  26 |   100 batches loss: 0.2037\n",
      "[Epoch  26]: Training loss: 0.218979 | Accuracy: 0.953175\n",
      "[Epoch  26]: Validation loss: 2.080412 | Accuracy: 0.573611 | Within 3: 0.776389\n",
      "epoch  27 |   100 batches loss: 0.1967\n",
      "[Epoch  27]: Training loss: 0.196650 | Accuracy: 0.958333\n",
      "[Epoch  27]: Validation loss: 2.020725 | Accuracy: 0.595833 | Within 3: 0.787500\n",
      "epoch  28 |   100 batches loss: 0.1704\n",
      "[Epoch  28]: Training loss: 0.174063 | Accuracy: 0.966667\n",
      "[Epoch  28]: Validation loss: 2.057629 | Accuracy: 0.594444 | Within 3: 0.784722\n",
      "epoch  29 |   100 batches loss: 0.1496\n",
      "[Epoch  29]: Training loss: 0.155290 | Accuracy: 0.970040\n",
      "[Epoch  29]: Validation loss: 2.167237 | Accuracy: 0.583333 | Within 3: 0.798611\n",
      "Best epoch:  27\n"
     ]
    }
   ],
   "source": [
    "mtrainer.run_train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21ef3f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 54.58333333333333 %\n",
      "Accuracy within top 3 results: 74.79166666666667 %\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, top_k = mtrainer.run_test(mtrainer.data.testloader, 3)\n",
    "print(f'Accuracy of the network on the test images: {test_acc*100} %')\n",
    "print(f'Accuracy within top 3 results: {top_k*100} %')\n",
    "\n",
    "# with 3 layer conv32-64, 3 layer conv64-128\n",
    "# Accuracy of the network on the test images: 57.15277777777777 %\n",
    "# Accuracy within top 3 results: 78.47222222222221 %\n",
    "\n",
    "# with 3 layer conv32-64, 3 layer conv64-128, without last maxpool\n",
    "# Accuracy of the network on the test images: 54.58333333333333 %\n",
    "# Accuracy within top 3 results: 74.79166666666667 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae836900",
   "metadata": {},
   "source": [
    "## CNN Model with skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "269bb8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model.text.residual_cnn' from '/Users/naomileow/Documents/school/CS5242/project/model/text/residual_cnn.py'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(residual_cnn)\n",
    "\n",
    "# conv3-16, conv16-32, conv32-64 with skip, conv64-128 conv with skip, no last maxpool\n",
    "# Accuracy of the network on the test images: 56.52777777777778 %\n",
    "# Accuracy within top 3 results: 77.91666666666667 %\n",
    "\n",
    "# conv with skips, 3 layer last 2 convs, no last maxpool\n",
    "# Accuracy of the network on the test images: 65.34722222222223 %\n",
    "# Accuracy within top 3 results: 85.41666666666666 %\n",
    "\n",
    "# conv with skips, 3 layer last 2 convs\n",
    "# Accuracy of the network on the test images: 59.375 %\n",
    "# Accuracy within top 3 results: 78.81944444444444 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efb6c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.text import trainer, residual_cnn\n",
    "\n",
    "batch_size = 32\n",
    "datastore = trainer.DataStore(data, batch_size)\n",
    "\n",
    "res_model = residual_cnn.ResidualCNN(len(data.categories), datastore.vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(res_model.parameters(), lr=5e-4)\n",
    "mtrainer = trainer.Trainer(res_model, optimizer, criterion, batch_size, datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2eff0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0 |   100 batches loss: 2.9941\n",
      "[Epoch   0]: Training loss: 2.958382 | Accuracy: 0.135317\n",
      "[Epoch   0]: Validation loss: 2.936275 | Accuracy: 0.123611 | Within 3: 0.325000\n",
      "epoch   1 |   100 batches loss: 2.8066\n",
      "[Epoch   1]: Training loss: 2.785748 | Accuracy: 0.195635\n",
      "[Epoch   1]: Validation loss: 2.778511 | Accuracy: 0.208333 | Within 3: 0.415278\n",
      "epoch   2 |   100 batches loss: 2.6332\n",
      "[Epoch   2]: Training loss: 2.578184 | Accuracy: 0.275595\n",
      "[Epoch   2]: Validation loss: 2.539781 | Accuracy: 0.284722 | Within 3: 0.502778\n",
      "epoch   3 |   100 batches loss: 2.3516\n",
      "[Epoch   3]: Training loss: 2.281804 | Accuracy: 0.375595\n",
      "[Epoch   3]: Validation loss: 2.243312 | Accuracy: 0.355556 | Within 3: 0.591667\n",
      "epoch   4 |   100 batches loss: 2.0438\n",
      "[Epoch   4]: Training loss: 2.000216 | Accuracy: 0.448611\n",
      "[Epoch   4]: Validation loss: 2.017163 | Accuracy: 0.423611 | Within 3: 0.661111\n",
      "epoch   5 |   100 batches loss: 1.7911\n",
      "[Epoch   5]: Training loss: 1.763269 | Accuracy: 0.510913\n",
      "[Epoch   5]: Validation loss: 1.821391 | Accuracy: 0.481944 | Within 3: 0.715278\n",
      "epoch   6 |   100 batches loss: 1.5975\n",
      "[Epoch   6]: Training loss: 1.566851 | Accuracy: 0.560516\n",
      "[Epoch   6]: Validation loss: 1.741582 | Accuracy: 0.494444 | Within 3: 0.736111\n",
      "epoch   7 |   100 batches loss: 1.4072\n",
      "[Epoch   7]: Training loss: 1.398063 | Accuracy: 0.610119\n",
      "[Epoch   7]: Validation loss: 1.633117 | Accuracy: 0.536111 | Within 3: 0.747222\n",
      "epoch   8 |   100 batches loss: 1.2784\n",
      "[Epoch   8]: Training loss: 1.267260 | Accuracy: 0.648611\n",
      "[Epoch   8]: Validation loss: 1.526355 | Accuracy: 0.561111 | Within 3: 0.744444\n",
      "epoch   9 |   100 batches loss: 1.1411\n",
      "[Epoch   9]: Training loss: 1.146098 | Accuracy: 0.679365\n",
      "[Epoch   9]: Validation loss: 1.468091 | Accuracy: 0.570833 | Within 3: 0.765278\n",
      "epoch  10 |   100 batches loss: 1.0429\n",
      "[Epoch  10]: Training loss: 1.038548 | Accuracy: 0.710317\n",
      "[Epoch  10]: Validation loss: 1.455592 | Accuracy: 0.580556 | Within 3: 0.777778\n",
      "epoch  11 |   100 batches loss: 0.9585\n",
      "[Epoch  11]: Training loss: 0.944858 | Accuracy: 0.739087\n",
      "[Epoch  11]: Validation loss: 1.415290 | Accuracy: 0.590278 | Within 3: 0.801389\n",
      "epoch  12 |   100 batches loss: 0.8410\n",
      "[Epoch  12]: Training loss: 0.860226 | Accuracy: 0.766667\n",
      "[Epoch  12]: Validation loss: 1.389067 | Accuracy: 0.600000 | Within 3: 0.797222\n",
      "epoch  13 |   100 batches loss: 0.7892\n",
      "[Epoch  13]: Training loss: 0.778586 | Accuracy: 0.787500\n",
      "[Epoch  13]: Validation loss: 1.362400 | Accuracy: 0.594444 | Within 3: 0.800000\n",
      "epoch  14 |   100 batches loss: 0.6984\n",
      "[Epoch  14]: Training loss: 0.718662 | Accuracy: 0.804960\n",
      "[Epoch  14]: Validation loss: 1.339538 | Accuracy: 0.626389 | Within 3: 0.808333\n",
      "epoch  15 |   100 batches loss: 0.6471\n",
      "[Epoch  15]: Training loss: 0.653712 | Accuracy: 0.827778\n",
      "[Epoch  15]: Validation loss: 1.334100 | Accuracy: 0.615278 | Within 3: 0.813889\n",
      "epoch  16 |   100 batches loss: 0.6022\n",
      "[Epoch  16]: Training loss: 0.596082 | Accuracy: 0.846032\n",
      "[Epoch  16]: Validation loss: 1.303241 | Accuracy: 0.625000 | Within 3: 0.812500\n",
      "epoch  17 |   100 batches loss: 0.5424\n",
      "[Epoch  17]: Training loss: 0.543179 | Accuracy: 0.861310\n",
      "[Epoch  17]: Validation loss: 1.303822 | Accuracy: 0.647222 | Within 3: 0.829167\n",
      "epoch  18 |   100 batches loss: 0.4975\n",
      "[Epoch  18]: Training loss: 0.496993 | Accuracy: 0.875397\n",
      "[Epoch  18]: Validation loss: 1.270367 | Accuracy: 0.655556 | Within 3: 0.841667\n",
      "epoch  19 |   100 batches loss: 0.4458\n",
      "[Epoch  19]: Training loss: 0.448576 | Accuracy: 0.889484\n",
      "[Epoch  19]: Validation loss: 1.305133 | Accuracy: 0.640278 | Within 3: 0.838889\n",
      "epoch  20 |   100 batches loss: 0.4075\n",
      "[Epoch  20]: Training loss: 0.411301 | Accuracy: 0.898214\n",
      "[Epoch  20]: Validation loss: 1.268274 | Accuracy: 0.652778 | Within 3: 0.830556\n",
      "epoch  21 |   100 batches loss: 0.3595\n",
      "[Epoch  21]: Training loss: 0.371303 | Accuracy: 0.910913\n",
      "[Epoch  21]: Validation loss: 1.274898 | Accuracy: 0.648611 | Within 3: 0.840278\n",
      "epoch  22 |   100 batches loss: 0.3454\n",
      "[Epoch  22]: Training loss: 0.335665 | Accuracy: 0.920635\n",
      "[Epoch  22]: Validation loss: 1.277109 | Accuracy: 0.659722 | Within 3: 0.845833\n",
      "epoch  23 |   100 batches loss: 0.3005\n",
      "[Epoch  23]: Training loss: 0.301912 | Accuracy: 0.930952\n",
      "[Epoch  23]: Validation loss: 1.326371 | Accuracy: 0.661111 | Within 3: 0.840278\n",
      "epoch  24 |   100 batches loss: 0.2668\n",
      "[Epoch  24]: Training loss: 0.271599 | Accuracy: 0.936905\n",
      "[Epoch  24]: Validation loss: 1.277935 | Accuracy: 0.659722 | Within 3: 0.850000\n",
      "epoch  25 |   100 batches loss: 0.2494\n",
      "[Epoch  25]: Training loss: 0.252029 | Accuracy: 0.942063\n",
      "[Epoch  25]: Validation loss: 1.370253 | Accuracy: 0.637500 | Within 3: 0.833333\n",
      "epoch  26 |   100 batches loss: 0.2253\n",
      "[Epoch  26]: Training loss: 0.223146 | Accuracy: 0.950397\n",
      "[Epoch  26]: Validation loss: 1.292662 | Accuracy: 0.666667 | Within 3: 0.847222\n",
      "epoch  27 |   100 batches loss: 0.1970\n",
      "[Epoch  27]: Training loss: 0.198431 | Accuracy: 0.960317\n",
      "[Epoch  27]: Validation loss: 1.298552 | Accuracy: 0.662500 | Within 3: 0.847222\n",
      "epoch  28 |   100 batches loss: 0.1615\n",
      "[Epoch  28]: Training loss: 0.177773 | Accuracy: 0.967262\n",
      "[Epoch  28]: Validation loss: 1.349101 | Accuracy: 0.662500 | Within 3: 0.848611\n",
      "epoch  29 |   100 batches loss: 0.1644\n",
      "[Epoch  29]: Training loss: 0.160362 | Accuracy: 0.971627\n",
      "[Epoch  29]: Validation loss: 1.300741 | Accuracy: 0.675000 | Within 3: 0.854167\n",
      "Best epoch:  29\n"
     ]
    }
   ],
   "source": [
    "mtrainer.run_train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1b7b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 65.34722222222223 %\n",
      "Accuracy within top 3 results: 85.41666666666666 %\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, top_k = mtrainer.run_test(mtrainer.data.testloader, 3)\n",
    "print(f'Accuracy of the network on the test images: {test_acc*100} %')\n",
    "print(f'Accuracy within top 3 results: {top_k*100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f5b32",
   "metadata": {},
   "source": [
    "## Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357823be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.text import trainer, attention_cnn\n",
    "\n",
    "batch_size = 32\n",
    "datastore = trainer.DataStore(data, batch_size)\n",
    "\n",
    "attn_model = attention_cnn.CNNWithAttention(len(data.categories), datastore.vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(attn_model.parameters(), lr=5e-4)\n",
    "mtrainer = trainer.Trainer(attn_model, optimizer, criterion, batch_size, datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87831eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs5242-proj/lib/python3.9/site-packages/torch/nn/functional.py:2380: UserWarning: The operator 'aten::_embedding_bag' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  ret, _, _, _ = torch.embedding_bag(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0 |   100 batches loss: 2.9842\n",
      "[Epoch   0]: Training loss: 2.960248 | Accuracy: 0.125595\n",
      "[Epoch   0]: Validation loss: 2.920455 | Accuracy: 0.119444 | Within 3: 0.318056\n",
      "epoch   1 |   100 batches loss: 2.8225\n",
      "[Epoch   1]: Training loss: 2.799329 | Accuracy: 0.181944\n",
      "[Epoch   1]: Validation loss: 2.859746 | Accuracy: 0.170833 | Within 3: 0.373611\n",
      "epoch   2 |   100 batches loss: 2.6480\n",
      "[Epoch   2]: Training loss: 2.605573 | Accuracy: 0.251389\n",
      "[Epoch   2]: Validation loss: 2.678330 | Accuracy: 0.233333 | Within 3: 0.437500\n",
      "epoch   3 |   100 batches loss: 2.3738\n",
      "[Epoch   3]: Training loss: 2.316778 | Accuracy: 0.350992\n",
      "[Epoch   3]: Validation loss: 2.257219 | Accuracy: 0.356944 | Within 3: 0.576389\n",
      "epoch   4 |   100 batches loss: 2.0720\n",
      "[Epoch   4]: Training loss: 2.027141 | Accuracy: 0.429563\n",
      "[Epoch   4]: Validation loss: 2.003838 | Accuracy: 0.408333 | Within 3: 0.658333\n",
      "epoch   5 |   100 batches loss: 1.8212\n",
      "[Epoch   5]: Training loss: 1.779457 | Accuracy: 0.497619\n",
      "[Epoch   5]: Validation loss: 1.833032 | Accuracy: 0.455556 | Within 3: 0.695833\n",
      "epoch   6 |   100 batches loss: 1.5932\n",
      "[Epoch   6]: Training loss: 1.571002 | Accuracy: 0.557937\n",
      "[Epoch   6]: Validation loss: 1.732890 | Accuracy: 0.497222 | Within 3: 0.737500\n",
      "epoch   7 |   100 batches loss: 1.4219\n",
      "[Epoch   7]: Training loss: 1.398079 | Accuracy: 0.603968\n",
      "[Epoch   7]: Validation loss: 1.615704 | Accuracy: 0.513889 | Within 3: 0.770833\n",
      "epoch   8 |   100 batches loss: 1.2567\n",
      "[Epoch   8]: Training loss: 1.248336 | Accuracy: 0.647222\n",
      "[Epoch   8]: Validation loss: 1.551687 | Accuracy: 0.531944 | Within 3: 0.777778\n",
      "epoch   9 |   100 batches loss: 1.1348\n",
      "[Epoch   9]: Training loss: 1.127671 | Accuracy: 0.675992\n",
      "[Epoch   9]: Validation loss: 1.658244 | Accuracy: 0.530556 | Within 3: 0.748611\n",
      "epoch  10 |   100 batches loss: 1.0344\n",
      "[Epoch  10]: Training loss: 1.022913 | Accuracy: 0.707937\n",
      "[Epoch  10]: Validation loss: 1.444292 | Accuracy: 0.577778 | Within 3: 0.791667\n",
      "epoch  11 |   100 batches loss: 0.9170\n",
      "[Epoch  11]: Training loss: 0.920847 | Accuracy: 0.745238\n",
      "[Epoch  11]: Validation loss: 1.412276 | Accuracy: 0.583333 | Within 3: 0.798611\n",
      "epoch  12 |   100 batches loss: 0.8241\n",
      "[Epoch  12]: Training loss: 0.834555 | Accuracy: 0.770040\n",
      "[Epoch  12]: Validation loss: 1.403869 | Accuracy: 0.588889 | Within 3: 0.795833\n",
      "epoch  13 |   100 batches loss: 0.7621\n",
      "[Epoch  13]: Training loss: 0.758019 | Accuracy: 0.789484\n",
      "[Epoch  13]: Validation loss: 1.348921 | Accuracy: 0.608333 | Within 3: 0.818056\n",
      "epoch  14 |   100 batches loss: 0.6778\n",
      "[Epoch  14]: Training loss: 0.689553 | Accuracy: 0.808135\n",
      "[Epoch  14]: Validation loss: 1.325401 | Accuracy: 0.601389 | Within 3: 0.809722\n",
      "epoch  15 |   100 batches loss: 0.6261\n",
      "[Epoch  15]: Training loss: 0.625904 | Accuracy: 0.825198\n",
      "[Epoch  15]: Validation loss: 1.365901 | Accuracy: 0.618056 | Within 3: 0.815278\n",
      "epoch  16 |   100 batches loss: 0.5686\n",
      "[Epoch  16]: Training loss: 0.565250 | Accuracy: 0.849206\n",
      "[Epoch  16]: Validation loss: 1.373430 | Accuracy: 0.612500 | Within 3: 0.813889\n",
      "epoch  17 |   100 batches loss: 0.4965\n",
      "[Epoch  17]: Training loss: 0.505677 | Accuracy: 0.866468\n",
      "[Epoch  17]: Validation loss: 1.394124 | Accuracy: 0.606944 | Within 3: 0.830556\n",
      "epoch  18 |   100 batches loss: 0.4605\n",
      "[Epoch  18]: Training loss: 0.456155 | Accuracy: 0.881548\n",
      "[Epoch  18]: Validation loss: 1.322617 | Accuracy: 0.638889 | Within 3: 0.830556\n",
      "epoch  19 |   100 batches loss: 0.4079\n",
      "[Epoch  19]: Training loss: 0.411559 | Accuracy: 0.899405\n",
      "[Epoch  19]: Validation loss: 1.380829 | Accuracy: 0.631944 | Within 3: 0.823611\n",
      "epoch  20 |   100 batches loss: 0.3604\n",
      "[Epoch  20]: Training loss: 0.372231 | Accuracy: 0.912698\n",
      "[Epoch  20]: Validation loss: 1.405628 | Accuracy: 0.620833 | Within 3: 0.820833\n",
      "epoch  21 |   100 batches loss: 0.3375\n",
      "[Epoch  21]: Training loss: 0.330555 | Accuracy: 0.921429\n",
      "[Epoch  21]: Validation loss: 1.374482 | Accuracy: 0.641667 | Within 3: 0.838889\n",
      "epoch  22 |   100 batches loss: 0.2790\n",
      "[Epoch  22]: Training loss: 0.291167 | Accuracy: 0.934524\n",
      "[Epoch  22]: Validation loss: 1.400940 | Accuracy: 0.625000 | Within 3: 0.829167\n",
      "epoch  23 |   100 batches loss: 0.2689\n",
      "[Epoch  23]: Training loss: 0.261248 | Accuracy: 0.943849\n",
      "[Epoch  23]: Validation loss: 1.396173 | Accuracy: 0.637500 | Within 3: 0.829167\n",
      "epoch  24 |   100 batches loss: 0.2246\n",
      "[Epoch  24]: Training loss: 0.231705 | Accuracy: 0.952579\n",
      "[Epoch  24]: Validation loss: 1.460432 | Accuracy: 0.637500 | Within 3: 0.826389\n",
      "epoch  25 |   100 batches loss: 0.2041\n",
      "[Epoch  25]: Training loss: 0.201539 | Accuracy: 0.959325\n",
      "[Epoch  25]: Validation loss: 1.438709 | Accuracy: 0.652778 | Within 3: 0.831944\n",
      "epoch  26 |   100 batches loss: 0.1679\n",
      "[Epoch  26]: Training loss: 0.173769 | Accuracy: 0.967857\n",
      "[Epoch  26]: Validation loss: 1.450378 | Accuracy: 0.627778 | Within 3: 0.825000\n",
      "epoch  27 |   100 batches loss: 0.1493\n",
      "[Epoch  27]: Training loss: 0.154823 | Accuracy: 0.970833\n",
      "[Epoch  27]: Validation loss: 1.479432 | Accuracy: 0.625000 | Within 3: 0.843056\n",
      "epoch  28 |   100 batches loss: 0.1164\n",
      "[Epoch  28]: Training loss: 0.120862 | Accuracy: 0.981944\n",
      "[Epoch  28]: Validation loss: 1.455036 | Accuracy: 0.661111 | Within 3: 0.840278\n",
      "epoch  29 |   100 batches loss: 0.0962\n",
      "[Epoch  29]: Training loss: 0.110140 | Accuracy: 0.983532\n",
      "[Epoch  29]: Validation loss: 1.528115 | Accuracy: 0.652778 | Within 3: 0.831944\n",
      "Best epoch:  28\n"
     ]
    }
   ],
   "source": [
    "mtrainer.run_train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f63dc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 60.55555555555555 %\n",
      "Accuracy within top 3 results: 81.875 %\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, top_k = mtrainer.run_test(mtrainer.data.testloader, 3)\n",
    "print(f'Accuracy of the network on the test images: {test_acc*100} %')\n",
    "print(f'Accuracy within top 3 results: {top_k*100} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d88d51e5feeef7cdbc38f54879bc8b14b595db7785db4e3b195d2593607adbb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
